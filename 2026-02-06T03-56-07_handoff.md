# Handoff: Qwen3-VL-Embedding investigation + offline A/B/C embedding evaluation

## Context

### Previous Conversation

- User request: investigate whether switching from current text-only RAG embeddings to Qwen3 multimodal embeddings (Qwen3-VL-Embedding) would improve font retrieval, including the idea of embedding a rendered glyph sheet image (alphanumeric + pangram) alongside text metadata, and whether embeddings can be generated locally on 2× RTX 3090 w/ NVLink.
- Output produced:
  - Assessment doc comparing baseline vs VL and proposing hybrid retrieval.
  - A full offline A/B/C evaluation harness with:
    - reproducible runbooks + progress tracking (SSoT)
    - baseline text-only eval (A)
    - VL eval (B1/B2) + hybrid fusion (C)
    - toy dataset validation
    - real 200-font dataset generation + proxy-label evaluation
    - committed results.

Key architectural decisions:
- Keep baseline text embedding pipeline intact for now (OpenRouter `qwen/qwen3-embedding-8b`). Baseline embedding entrypoint is [`generateEmbedding()`](src/lib/ai/embeddings.ts:4).
- For VL, prefer **correctness-first** embedding generation using Transformers + `qwen-vl-utils` (instead of vLLM pooling) due to reported parity concerns.
- For evaluation, implement 3 variants:
  - A: text-only embeddings
  - B1: VL vision-only (glyph image only)
  - B2: VL vision + light structured text
  - C: hybrid fusion of A + B2, with α sweep.

Rejected / deferred alternatives:
- Immediate production replacement of text embeddings with VL embeddings (deferred; hybrid recommended).
- Using vLLM pooling for embeddings as the primary evaluation backend (deferred pending parity validation).
- Claiming proxy-label results measure “visual style match” (explicitly avoided; proxy labels measure metadata/category alignment only).

### Current Work

- Objective before last instruction: run full A/B/C evaluation and report results.
- Current status: offline evaluation harness is implemented, validated on toy data, and executed on a real 200-font dataset with committed metrics and artifacts.
- Completion phase (for offline eval harness): ~90% complete.
  - “Verified harness + proxy-labeled 200-font results” is done.
  - Remaining to fully answer product question: run on target GPU model (ideally `Qwen/Qwen3-VL-Embedding-8B`) and add a small human-labeled “visual intent” query set.
- Active mode: Orchestrator.

## Key Technical Concepts

### Existing product embedding/RAG pipeline (baseline)

- Embedding model: OpenRouter `qwen/qwen3-embedding-8b` via [`generateEmbedding()`](src/lib/ai/embeddings.ts:4).
- Font doc embedding text schema (seed-time): `Name / Category / Tags / Description` in [`contextString`](scripts/seed-fonts.ts:193).
- Query embedding text schema (runtime): raw user `message` via [`POST()`](src/app/api/search/route.ts:37) and `generateEmbedding(message)` ([`POST()`](src/app/api/search/route.ts:50)).
- Vector DB: Supabase pgvector with `vector(4096)` and RPCs in [`003_upgrade_vector_dimension.sql`](supabase/migrations/003_upgrade_vector_dimension.sql:1) including [`match_fonts()`](supabase/migrations/003_upgrade_vector_dimension.sql:6) and [`match_searches()`](supabase/migrations/003_upgrade_vector_dimension.sql:35).

### VL embedding concept for fonts

- Represent each font by a deterministic “glyph sheet” PNG (alphanumerics + pangram) and optionally attach a short structured text payload.
- Embed docs using Qwen3-VL-Embedding; embed queries using text-only in the same embedding space.
- Evidence so far indicates B2 (image+text) > B1 (image-only), suggesting a text anchor is beneficial.

### Local inference feasibility (2×3090 + NVLink)

- NVLink improves inter-GPU bandwidth for tensor-parallel collectives but does not transparently pool VRAM in typical PyTorch workflows.
- For correctness-first evaluation we used Transformers + `qwen-vl-utils`; multi-GPU sharding is handled via `device_map="auto"` (documented in [`LOCAL_GPU_SETUP.md`](research/ab-eval/LOCAL_GPU_SETUP.md:1)).
- In the recorded 200-font run, VL embeddings were computed on CPU using `Qwen/Qwen3-VL-Embedding-2B` due to lack of CUDA on the execution machine; this is a key handoff risk/limitation for interpreting absolute numbers.

## Relevant Files and Code (File System Impact Registry)

### Assessment + planning docs

- [`_05_guides/2026-02-04_qwen3-vl-embedding_assessment.md`](_05_guides/2026-02-04_qwen3-vl-embedding_assessment.md:1)
  - Analysis of baseline vs VL embeddings; recommends hybrid retrieval and a short offline A/B.

- [`_05_guides/2026-02-05_offline-ab-eval-plan_qwen3-vl.md`](_05_guides/2026-02-05_offline-ab-eval-plan_qwen3-vl.md:1)
  - Concrete offline evaluation plan: corpus, query/label strategy, variants A/B/C, metrics.

### SSoT runbook + tracking (created)

- [`research/ab-eval/README.md`](research/ab-eval/README.md:1)
  - Entry point to evaluation workflow.

- [`research/ab-eval/RUNBOOK.md`](research/ab-eval/RUNBOOK.md:1)
  - How to generate datasets and run evaluation.

- [`research/ab-eval/PROGRESS.md`](research/ab-eval/PROGRESS.md:1)
  - Checklist + status log.

- [`research/ab-eval/DECISIONS.md`](research/ab-eval/DECISIONS.md:1)
  - Decision log template.

### Evaluation scripts (created/updated)

- Glyph sheet rendering:
  - [`render_glyph_sheet.py`](research/ab-eval/py/render_glyph_sheet.py:1)

- Baseline embeddings (OpenRouter text embeddings):
  - [`embed_openrouter_text.py`](research/ab-eval/py/embed_openrouter_text.py:1)

- VL embeddings:
  - Smoke test / utility: [`embed_qwen3_vl.py`](research/ab-eval/py/embed_qwen3_vl.py:1)
  - Batch embedding: [`embed_qwen3_vl_batch.py`](research/ab-eval/py/embed_qwen3_vl_batch.py:1)

- Scoring:
  - Baseline scoring: [`score_retrieval.py`](research/ab-eval/py/score_retrieval.py:1)
  - Multi-variant scoring + hybrid α sweep: [`score_all_variants.py`](research/ab-eval/py/score_all_variants.py:1)
    - Notable bug fix during toy run: scorer assumed >=10 results; fixed to handle small corpora.

- Runners:
  - Text-only runner: [`run_all_text.py`](research/ab-eval/py/run_all_text.py:1)
  - Unified runner for A/B/C: [`run_all.py`](research/ab-eval/py/run_all.py:1)
    - Later updated to support `--dataset 200` and `--model` override for VL model selection.

### Datasets and results artifacts (created)

- Toy dataset:
  - [`corpus.toy.json`](research/ab-eval/data/corpus.toy.json:1)
  - [`queries.toy.json`](research/ab-eval/data/queries.toy.json:1)
  - [`labels.toy.json`](research/ab-eval/data/labels.toy.json:1)

- 200-font dataset + proxy labels:
  - Corpus: [`corpus.200.json`](research/ab-eval/data/corpus.200.json:1)
  - Queries: [`queries.200.json`](research/ab-eval/data/queries.200.json:1)
  - Labels: [`labels.200.json`](research/ab-eval/data/labels.200.json:1)

- Dataset generators:
  - Build corpus: [`build_corpus_google_fonts.py`](research/ab-eval/py/build_corpus_google_fonts.py:1)
    - Implementation note: uses Fontsource API to acquire Google Fonts and file URLs without a Google API key.
  - Build queries/labels: [`build_queries_labels_metadata.py`](research/ab-eval/py/build_queries_labels_metadata.py:1)

- Results (recorded):
  - Combined report: [`report_all.md`](research/ab-eval/out/report_all.md:1)
  - Latest summary: [`LATEST_RESULTS.md`](research/ab-eval/out/LATEST_RESULTS.md:1)

### Production code referenced (no changes made in this work)

- Text embedding call: [`generateEmbedding()`](src/lib/ai/embeddings.ts:4)
- Seed-time embedding input string: [`contextString`](scripts/seed-fonts.ts:193)
- Search route embedding + RPC usage: [`POST()`](src/app/api/search/route.ts:37)
- Vector schema/RPCs: [`match_fonts()`](supabase/migrations/003_upgrade_vector_dimension.sql:6)

## Problem Solving / Validation State

### Solved / validated

- Implemented and validated an end-to-end offline evaluation harness:
  - A: OpenRouter text embeddings
  - B1/B2: Qwen3-VL embeddings (vision-only vs vision+text)
  - C: α-swept hybrid fusion A+B2
- Confirmed harness on toy dataset and then executed on 200-font dataset.

### Known limitations / edge cases

- 200-font evaluation uses **metadata-derived proxy labels** (category/subsets). This validates harness behavior and gives directional signal, but it does not fully measure nuanced visual matching.
- VL results recorded for the 200-font run used `Qwen/Qwen3-VL-Embedding-2B` on CPU (slow; ~50 minutes). The key next validation is running `Qwen/Qwen3-VL-Embedding-8B` on the target 2×3090 setup.
- Dependency brittleness: VL requirements are heavier; deps were split into separate files.

### Validation outputs and observed metrics (200-font proxy-labeled run)

From [`report_all.md`](research/ab-eval/out/report_all.md:1) and [`LATEST_RESULTS.md`](research/ab-eval/out/LATEST_RESULTS.md:1):

- Global metrics:
  - A (text-only): Recall@10 0.1764, Recall@20 0.3454, MRR@10 0.7000
  - B1 (image-only): Recall@10 0.0800, Recall@20 0.1776, MRR@10 0.4729
  - B2 (image + text): Recall@10 0.2893, Recall@20 0.4657, MRR@10 0.9222
  - C (hybrid α=0.5): Recall@10 0.3170, Recall@20 0.5127, MRR@10 0.9667
  - Best α (sweep): α=0.4 → Recall@10 0.3326, MRR@10 1.0000

Interpretation:
- In this proxy benchmark, B2 and hybrid C outperform A, while B1 underperforms.

## Pending Tasks and Next Steps

### Roadmap

- Re-run the 200-font evaluation on the actual target hardware (2×3090) and target VL model (`Qwen/Qwen3-VL-Embedding-8B`) to confirm the effect size and performance characteristics.
- Add a small human-labeled dataset focused on *visual intent* prompts (x-height, counters, contrast, terminals, width, etc.) and re-run A/B2/C; this becomes the real go/no-go signal for product improvement.
- If hybrid continues to win, plan a production rollout as a hybrid retrieval option (store a second vector column for VL doc embeddings and fuse scores at query time).

### Verbatim Last Instruction

> "Your task is to create a detailed summary of the conversation so far... Generate a timestamped markdown file in the project root directory. Filename format: `YYYY-MM-DDTHH-mm-ss_handoff.md`"

### Immediate Next Action

- (Post-handoff) Run `Qwen/Qwen3-VL-Embedding-8B` evaluation on the 2×3090 host per [`LOCAL_GPU_SETUP.md`](research/ab-eval/LOCAL_GPU_SETUP.md:1) and append results to [`LATEST_RESULTS.md`](research/ab-eval/out/LATEST_RESULTS.md:1), then log a decision in [`DECISIONS.md`](research/ab-eval/DECISIONS.md:1).

### Handoff Risks

- Environment variables:
  - `OPENROUTER_API_KEY` required to run Variant A embeddings.
  - GPU/CUDA stack required to run VL model at reasonable speed.
- Runtime expectations:
  - CPU VL embedding runs are slow; GPU is strongly preferred for 8B.
- Interpretation risk:
  - Proxy labels (category/subsets) do not fully measure typography visual similarity; a human-labeled “visual intent” set is required before making a production switch.

## Commits created during this work (reference)

- `5488de8` — docs: add offline A/B eval runbook
- `8ef084f` — feat: add offline text embedding eval harness
- `7cb6ca1` — chore: add local Qwen3-VL embedding smoke test
- `7e17fb3` — feat: add VL + hybrid eval variants
- `bea3d42` — feat: add 200-font corpus and metadata labels
- `2eed27c` — chore: record 200-font ABC eval results

